{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv matplotlib pandas -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "# Cargar variables de entorno desde el archivo .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame para o3:\n",
      "           day    country  o3_daily_avg  o3_daily_max  o3_daily_min\n",
      "0   2023-11-14  Amsterdam            24            29            18\n",
      "1   2023-11-15  Amsterdam            23            28            17\n",
      "2   2023-11-16  Amsterdam             7            22             1\n",
      "3   2023-11-17  Amsterdam             4             8             1\n",
      "4   2023-11-18  Amsterdam             5             5             5\n",
      "5   2023-11-12     Berlin             8            14             4\n",
      "6   2023-11-13     Berlin            10            20             3\n",
      "7   2023-11-14     Berlin            23            27            20\n",
      "8   2023-11-15     Berlin            10            20             1\n",
      "9   2023-11-16     Berlin            13            23             5\n",
      "10  2023-11-17     Berlin            10            20             3\n",
      "11  2023-11-18     Berlin            14            14            14\n",
      "12  2023-11-14      Paris            24            28            21\n",
      "13  2023-11-15      Paris            17            25            11\n",
      "14  2023-11-16      Paris             8            19             1\n",
      "15  2023-11-17      Paris             9            26             1\n",
      "16  2023-11-18      Paris             6             6             6\n",
      "----------------------------------------\n",
      "DataFrame para pm10:\n",
      "           day    country  pm10_daily_avg  pm10_daily_max  pm10_daily_min\n",
      "0   2023-11-14  Amsterdam              13              19               9\n",
      "1   2023-11-15  Amsterdam              12              15               7\n",
      "2   2023-11-16  Amsterdam              15              25               7\n",
      "3   2023-11-17  Amsterdam              22              32              10\n",
      "4   2023-11-18  Amsterdam              12              13              12\n",
      "5   2023-11-12     Berlin              14              16              10\n",
      "6   2023-11-13     Berlin              14              21               5\n",
      "7   2023-11-14     Berlin              10              13               7\n",
      "8   2023-11-15     Berlin              10              17               7\n",
      "9   2023-11-16     Berlin               8              13               4\n",
      "10  2023-11-17     Berlin              14              17              11\n",
      "11  2023-11-18     Berlin              13              13              13\n",
      "12  2023-11-14      Paris              10              12               5\n",
      "13  2023-11-15      Paris              13              16               9\n",
      "14  2023-11-16      Paris              17              26               9\n",
      "15  2023-11-17      Paris              16              21               8\n",
      "16  2023-11-18      Paris              20              20              18\n",
      "----------------------------------------\n",
      "DataFrame para pm25:\n",
      "           day    country  pm25_daily_avg  pm25_daily_max  pm25_daily_min\n",
      "0   2023-11-14  Amsterdam              23              25              20\n",
      "1   2023-11-15  Amsterdam              22              25              16\n",
      "2   2023-11-16  Amsterdam              40              68              12\n",
      "3   2023-11-17  Amsterdam              62              81              36\n",
      "4   2023-11-18  Amsterdam              42              47              42\n",
      "5   2023-11-12     Berlin              49              53              35\n",
      "6   2023-11-13     Berlin              43              61              16\n",
      "7   2023-11-14     Berlin              29              38              23\n",
      "8   2023-11-15     Berlin              33              53              20\n",
      "9   2023-11-16     Berlin              28              40              10\n",
      "10  2023-11-17     Berlin              50              57              36\n",
      "11  2023-11-18     Berlin              48              50              48\n",
      "12  2023-11-14      Paris              25              29              20\n",
      "13  2023-11-15      Paris              35              49              20\n",
      "14  2023-11-16      Paris              50              68              29\n",
      "15  2023-11-17      Paris              46              61              21\n",
      "16  2023-11-18      Paris              58              58              54\n",
      "----------------------------------------\n",
      "DataFrame para uvi:\n",
      "           day    country  uvi_daily_avg  uvi_daily_max  uvi_daily_min\n",
      "0   2022-10-24  Amsterdam              0              0              0\n",
      "1   2021-07-03     Berlin              1              4              0\n",
      "2   2021-07-04     Berlin              1              5              0\n",
      "3   2021-07-05     Berlin              1              4              0\n",
      "4   2021-07-06     Berlin              1              7              0\n",
      "5   2021-07-07     Berlin              1              6              0\n",
      "6   2021-07-08     Berlin              1              5              0\n",
      "7   2021-07-09     Berlin              2              5              0\n",
      "8   2021-02-26      Paris              0              1              0\n",
      "9   2021-02-27      Paris              0              3              0\n",
      "10  2021-02-28      Paris              0              2              0\n",
      "11  2021-03-01      Paris              0              2              0\n",
      "12  2021-03-02      Paris              0              2              0\n",
      "13  2021-03-03      Paris              1              2              0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def fetch_air_quality(city):\n",
    "    token = os.getenv(\"API_TOKEN\")\n",
    "    url = f\"https://api.waqi.info/feed/{city}/?token={token}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = json.loads(response.text)\n",
    "        if data['status'] == 'ok':\n",
    "            return data['data']\n",
    "        else:\n",
    "            return f\"Error en la API: {data['status']}\"\n",
    "    elif response.status_code == 400:\n",
    "        return \"Solicitud no válida\"\n",
    "    elif response.status_code == 401:\n",
    "        return \"Token inválido\"\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\"\n",
    "\n",
    "# Lista de ciudades\n",
    "cities = [\"amsterdam\", \"berlin\", \"paris\"]\n",
    "\n",
    "# Contaminantes para los que se generará un DataFrame\n",
    "contaminants = ['o3', 'pm10', 'pm25', 'uvi']\n",
    "\n",
    "def create_dataframe_for_contaminant(contaminant, cities_data):\n",
    "    data_list = []\n",
    "    for city, city_data in cities_data.items():\n",
    "        if 'forecast' in city_data and 'daily' in city_data['forecast'] and contaminant in city_data['forecast']['daily']:\n",
    "            for forecast in city_data['forecast']['daily'][contaminant]:\n",
    "                data_list.append({\n",
    "                    'day': forecast['day'],\n",
    "                    'country': city.capitalize(),\n",
    "                    f'{contaminant}_daily_avg': forecast['avg'],\n",
    "                    f'{contaminant}_daily_max': forecast['max'],\n",
    "                    f'{contaminant}_daily_min': forecast['min']\n",
    "                })\n",
    "    return pd.DataFrame(data_list)\n",
    "\n",
    "# Recopilar datos de calidad del aire para cada ciudad\n",
    "cities_data = {city: fetch_air_quality(city) for city in cities}\n",
    "\n",
    "# Diccionario para almacenar los DataFrames de cada contaminante\n",
    "dataframes = {}\n",
    "\n",
    "# Crear un DataFrame para cada contaminante\n",
    "for contaminant in contaminants:\n",
    "    df = create_dataframe_for_contaminant(contaminant, cities_data)\n",
    "    dataframes[contaminant] = df\n",
    "    print(f\"DataFrame para {contaminant}:\")\n",
    "    print(df)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_en_redshift(conn, table_name, dataframe):\n",
    "    dtypes = dataframe.dtypes\n",
    "    cols = list(dtypes.index)\n",
    "    tipos = list(dtypes.values)\n",
    "    type_map = {'int64': 'INT', 'int32': 'INT', 'float64': 'FLOAT', 'object': 'VARCHAR(50)', 'bool': 'BOOLEAN'}\n",
    "    sql_dtypes = [type_map[str(dtype)] for dtype in tipos]\n",
    "\n",
    "    # Encerrar los nombres de columna entre comillas dobles para manejar caracteres especiales\n",
    "    column_defs = [f'\"{name}\" {data_type}' for name, data_type in zip(cols, sql_dtypes)]\n",
    "\n",
    "    table_schema = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            {', '.join(column_defs)}\n",
    "        );\n",
    "        \"\"\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(table_schema)\n",
    "    values = [tuple(x) for x in dataframe.to_numpy()]\n",
    "\n",
    "    # Encerrar los nombres de columna entre comillas dobles en la consulta SQL\n",
    "    insert_sql = \"INSERT INTO \" + table_name + \" (\" + \", \".join(['\"' + col + '\"' for col in cols]) + \") VALUES %s\"\n",
    "    cur.execute(\"BEGIN\")\n",
    "    execute_values(cur, insert_sql, values)\n",
    "    cur.execute(\"COMMIT\")\n",
    "    print('Proceso terminado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Redshift successfully!\n",
      "Proceso terminado\n",
      "Datos para o3 cargados en Redshift.\n",
      "Proceso terminado\n",
      "Datos para pm10 cargados en Redshift.\n",
      "Proceso terminado\n",
      "Datos para pm25 cargados en Redshift.\n",
      "Proceso terminado\n",
      "Datos para uvi cargados en Redshift.\n"
     ]
    }
   ],
   "source": [
    "# Función para conectarse a Redshift\n",
    "def connect_to_redshift():\n",
    "    db_host = os.getenv(\"DB_HOST\")\n",
    "    db_name = os.getenv(\"DB_NAME\")\n",
    "    db_user = os.getenv(\"DB_USER\")\n",
    "    db_port = os.getenv(\"DB_PORT\")\n",
    "    db_password = os.getenv(\"DB_PASSWORD_FILE\")  # Asumiendo que cargas la contraseña directamente\n",
    "\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=db_host,\n",
    "            dbname=db_name,\n",
    "            user=db_user,\n",
    "            password=db_password,\n",
    "            port=db_port\n",
    "        )\n",
    "        print(\"Connected to Redshift successfully!\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(\"Unable to connect to Redshift.\")\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# Función principal\n",
    "if __name__ == \"__main__\":\n",
    "    conn = connect_to_redshift()\n",
    "    if conn:\n",
    "        # Suponiendo que dataframes es tu diccionario de DataFrames\n",
    "        for contaminant, df in dataframes.items():\n",
    "            table_name = f\"air_quality_{contaminant}\"\n",
    "            cargar_en_redshift(conn, table_name, df)\n",
    "            print(f\"Datos para {contaminant} cargados en Redshift.\")\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
